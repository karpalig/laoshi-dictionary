#!/usr/bin/env python3
"""
–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä HSK —Å–ª–æ–≤–∞—Ä–µ–π –∏–∑ github.com/clem109/hsk-vocabulary
–≤ –Ω–∞—à —Ñ–æ—Ä–º–∞—Ç JSON —Å —Ä—É—Å—Å–∫–∏–º–∏ –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏
"""

import json
import requests
import re
from typing import List, Dict

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ pinyin —Å —Ç–æ–Ω–∞–º–∏ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
TONE_MARKS = {
    'ƒÅ': 'a1', '√°': 'a2', '«é': 'a3', '√†': 'a4', 'a': 'a',
    'ƒì': 'e1', '√©': 'e2', 'ƒõ': 'e3', '√®': 'e4', 'e': 'e',
    'ƒ´': 'i1', '√≠': 'i2', '«ê': 'i3', '√¨': 'i4', 'i': 'i',
    '≈ç': 'o1', '√≥': 'o2', '«í': 'o3', '√≤': 'o4', 'o': 'o',
    '≈´': 'u1', '√∫': 'u2', '«î': 'u3', '√π': 'u4', 'u': 'u',
    '«ñ': 'v1', '«ò': 'v2', '«ö': 'v3', '«ú': 'v4', '√º': 'v',
}

# –ë–∞–∑–æ–≤—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã (–∞–Ω–≥–ª–∏–π—Å–∫–∏–π -> —Ä—É—Å—Å–∫–∏–π)
COMMON_TRANSLATIONS = {
    'to love': '–ª—é–±–∏—Ç—å',
    'to be fond of': '–Ω—Ä–∞–≤–∏—Ç—å—Å—è',
    'to like': '–ª—é–±–∏—Ç—å',
    'eight': '–≤–æ—Å–µ–º—å',
    'father': '–æ—Ç–µ—Ü',
    'papa': '–ø–∞–ø–∞',
    'cup': '—á–∞—à–∫–∞',
    'glass': '—Å—Ç–∞–∫–∞–Ω',
    'Beijing': '–ü–µ–∫–∏–Ω',
    'book': '–∫–Ω–∏–≥–∞',
    'not': '–Ω–µ',
    "you're welcome": '–ø–æ–∂–∞–ª—É–π—Å—Ç–∞',
    'impolite': '–Ω–µ–≤–µ–∂–ª–∏–≤—ã–π',
    'tea': '—á–∞–π',
    'to eat': '–µ—Å—Ç—å',
    'taxi': '—Ç–∞–∫—Å–∏',
    'to phone': '–∑–≤–æ–Ω–∏—Ç—å',
    'telephone': '—Ç–µ–ª–µ—Ñ–æ–Ω',
    'big': '–±–æ–ª—å—à–æ–π',
    'particle': '—á–∞—Å—Ç–∏—Ü–∞',
    "o'clock": '—á–∞—Å',
    'point': '—Ç–æ—á–∫–∞',
    'computer': '–∫–æ–º–ø—å—é—Ç–µ—Ä',
    'television': '—Ç–µ–ª–µ–≤–∏–∑–æ—Ä',
    'TV': '–¢–í',
    'movie': '—Ñ–∏–ª—å–º',
    'film': '–∫–∏–Ω–æ',
    'thing': '–≤–µ—â—å',
    'stuff': '–ø—Ä–µ–¥–º–µ—Ç',
    'all': '–≤—Å–µ',
    'both': '–æ–±–∞',
    'to read': '—á–∏—Ç–∞—Ç—å',
    'sorry': '–∏–∑–≤–∏–Ω–∏—Ç–µ',
    'excuse me': '–ø—Ä–æ—Å—Ç–∏—Ç–µ',
    'many': '–º–Ω–æ–≥–æ',
    'much': '–º–Ω–æ–≥–æ',
    'how many': '—Å–∫–æ–ª—å–∫–æ',
    'how much': '—Å–∫–æ–ª—å–∫–æ',
    'son': '—Å—ã–Ω',
    'two': '–¥–≤–∞',
    'restaurant': '—Ä–µ—Å—Ç–æ—Ä–∞–Ω',
    'airplane': '—Å–∞–º–æ–ª–µ—Ç',
    'plane': '—Å–∞–º–æ–ª–µ—Ç',
    'minute': '–º–∏–Ω—É—Ç–∞',
    'happy': '—Ä–∞–¥–æ—Å—Ç–Ω—ã–π',
    'glad': '–≤–µ—Å–µ–ª—ã–π',
    'classifier': '—Å—á–µ—Ç–Ω–æ–µ —Å–ª–æ–≤–æ',
    'measure word': '—Å—á–µ—Ç–Ω–æ–µ —Å–ª–æ–≤–æ',
    'to work': '—Ä–∞–±–æ—Ç–∞—Ç—å',
    'work': '—Ä–∞–±–æ—Ç–∞',
    'dog': '—Å–æ–±–∞–∫–∞',
    'Chinese language': '–∫–∏—Ç–∞–π—Å–∫–∏–π —è–∑—ã–∫',
    'good': '—Ö–æ—Ä–æ—à–∏–π',
    'well': '—Ö–æ—Ä–æ—à–æ',
    'number': '–Ω–æ–º–µ—Ä',
    'date': '–¥–∞—Ç–∞',
    'to drink': '–ø–∏—Ç—å',
    'and': '–∏',
    'with': '—Å',
    'very': '–æ—á–µ–Ω—å',
    'behind': '—Å–∑–∞–¥–∏',
    'back': '–ø–æ–∑–∞–¥–∏',
    'to return': '–≤–æ–∑–≤—Ä–∞—â–∞—Ç—å—Å—è',
    'can': '—É–º–µ—Ç—å',
    'to be able to': '–º–æ—á—å',
    'how many': '—Å–∫–æ–ª—å–∫–æ',
    'home': '–¥–æ–º',
    'family': '—Å–µ–º—å—è',
    'to call': '–∑–≤–∞—Ç—å',
    'to be called': '–Ω–∞–∑—ã–≤–∞—Ç—å—Å—è',
    'today': '—Å–µ–≥–æ–¥–Ω—è',
    'nine': '–¥–µ–≤—è—Ç—å',
    'to open': '–æ—Ç–∫—Ä—ã–≤–∞—Ç—å',
    'to see': '—Å–º–æ—Ç—Ä–µ—Ç—å',
    'to look': '—Å–º–æ—Ç—Ä–µ—Ç—å',
    'to watch': '—Å–º–æ—Ç—Ä–µ—Ç—å',
    'yuan': '—é–∞–Ω—å',
    'to come': '–ø—Ä–∏—Ö–æ–¥–∏—Ç—å',
    'teacher': '—É—á–∏—Ç–µ–ª—å',
    'cold': '—Ö–æ–ª–æ–¥–Ω—ã–π',
    'inside': '–≤–Ω—É—Ç—Ä–∏',
    'in': '–≤',
    'six': '—à–µ—Å—Ç—å',
    'mother': '–º–∞–º–∞',
    'mom': '–º–∞–º–∞',
    'question particle': '–≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —á–∞—Å—Ç–∏—Ü–∞',
    'to buy': '–ø–æ–∫—É–ø–∞—Ç—å',
    'cat': '–∫–æ—à–∫–∞',
    "it doesn't matter": '–Ω–∏—á–µ–≥–æ',
    'never mind': '–Ω–µ –≤–∞–∂–Ω–æ',
    'to not have': '–Ω–µ –∏–º–µ—Ç—å',
    "don't have": '–Ω–µ—Ç',
    'rice': '—Ä–∏—Å',
    'cooked rice': '–≤–∞—Ä–µ–Ω—ã–π —Ä–∏—Å',
    'name': '–∏–º—è',
    'tomorrow': '–∑–∞–≤—Ç—Ä–∞',
    'which': '–∫–æ—Ç–æ—Ä—ã–π',
    'what': '–∫–∞–∫–æ–π',
    'where': '–≥–¥–µ',
    'that': '—Ç–æ—Ç',
    'to be able': '–º–æ—á—å',
    'you': '—Ç—ã',
    'year': '–≥–æ–¥',
    'daughter': '–¥–æ—á—å',
    'friend': '–¥—Ä—É–≥',
    'pretty': '–∫—Ä–∞—Å–∏–≤—ã–π',
    'beautiful': '–∫—Ä–∞—Å–∏–≤—ã–π',
    'apple': '—è–±–ª–æ–∫–æ',
    'seven': '—Å–µ–º—å',
    'front': '–≤–ø–µ—Ä–µ–¥–∏',
    'before': '–ø–µ—Ä–µ–¥',
    'money': '–¥–µ–Ω—å–≥–∏',
    'please': '–ø–æ–∂–∞–ª—É–π—Å—Ç–∞',
    'to go': '–∏–¥—Ç–∏',
    'hot': '–≥–æ—Ä—è—á–∏–π',
    'person': '—á–µ–ª–æ–≤–µ–∫',
    'people': '–ª—é–¥–∏',
    'to know': '–∑–Ω–∞—Ç—å',
    'to recognize': '—É–∑–Ω–∞–≤–∞—Ç—å',
    'three': '—Ç—Ä–∏',
    'store': '–º–∞–≥–∞–∑–∏–Ω',
    'shop': '–º–∞–≥–∞–∑–∏–Ω',
    'up': '–≤–µ—Ä—Ö',
    'on': '–Ω–∞–≤–µ—Ä—Ö—É',
    'morning': '—É—Ç—Ä–æ',
    'few': '–º–∞–ª–æ',
    'little': '–Ω–µ–º–Ω–æ–≥–æ',
    'who': '–∫—Ç–æ',
    'what': '—á—Ç–æ',
    'ten': '–¥–µ—Å—è—Ç—å',
    'time': '–≤—Ä–µ–º—è',
    'to be': '–±—ã—Ç—å',
    'yes': '–¥–∞',
    'water': '–≤–æ–¥–∞',
    'fruit': '—Ñ—Ä—É–∫—Ç—ã',
    'to sleep': '—Å–ø–∞—Ç—å',
    'to say': '–≥–æ–≤–æ—Ä–∏—Ç—å',
    'to speak': '–≥–æ–≤–æ—Ä–∏—Ç—å',
    'four': '—á–µ—Ç—ã—Ä–µ',
    'years old': '–ª–µ—Ç',
    'age': '–≤–æ–∑—Ä–∞—Å—Ç',
    'he': '–æ–Ω',
    'she': '–æ–Ω–∞',
    'too': '—Å–ª–∏—à–∫–æ–º',
    'weather': '–ø–æ–≥–æ–¥–∞',
    'to listen': '—Å–ª—É—à–∞—Ç—å',
    'to hear': '—Å–ª—ã—à–∞—Ç—å',
    'classmate': '–æ–¥–Ω–æ–∫–ª–∞—Å—Å–Ω–∏–∫',
    'hello': '–∞–ª–ª–æ',
    'hey': '—ç–π',
    'I': '—è',
    'me': '—è',
    'we': '–º—ã',
    'us': '–º—ã',
    'five': '–ø—è—Ç—å',
    'to be fond of': '–Ω—Ä–∞–≤–∏—Ç—å—Å—è',
    'down': '–Ω–∏–∑',
    'under': '–≤–Ω–∏–∑—É',
    'afternoon': '–¥–µ–Ω—å',
    'to rain': '–∏–¥–µ—Ç –¥–æ–∂–¥—å',
    'Mr.': '–≥–æ—Å–ø–æ–¥–∏–Ω',
    'mister': '–º–∏—Å—Ç–µ—Ä',
    'now': '—Å–µ–π—á–∞—Å',
    'to think': '–¥—É–º–∞—Ç—å',
    'to want': '—Ö–æ—Ç–µ—Ç—å',
    'small': '–º–∞–ª–µ–Ω—å–∫–∏–π',
    'miss': '–º–∏—Å—Å',
    'some': '–Ω–µ—Å–∫–æ–ª—å–∫–æ',
    'a little': '–Ω–µ–º–Ω–æ–≥–æ',
    'to write': '–ø–∏—Å–∞—Ç—å',
    'thank you': '—Å–ø–∞—Å–∏–±–æ',
    'thanks': '—Å–ø–∞—Å–∏–±–æ',
    'week': '–Ω–µ–¥–µ–ª—è',
    'student': '—Å—Ç—É–¥–µ–Ω—Ç',
    'pupil': '—É—á–µ–Ω–∏–∫',
    'to study': '—É—á–∏—Ç—å—Å—è',
    'to learn': '–∏–∑—É—á–∞—Ç—å',
    'school': '—à–∫–æ–ª–∞',
    'one': '–æ–¥–∏–Ω',
    'a bit': '–Ω–µ–º–Ω–æ–≥–æ',
    'clothing': '–æ–¥–µ–∂–¥–∞',
    'clothes': '–æ–¥–µ–∂–¥–∞',
    'doctor': '–≤—Ä–∞—á',
    'hospital': '–±–æ–ª—å–Ω–∏—Ü–∞',
    'chair': '—Å—Ç—É–ª',
    'to have': '–∏–º–µ—Ç—å',
    'month': '–º–µ—Å—è—Ü',
    'at': '–≤',
    'to be at': '–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è',
    'goodbye': '–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è',
    'how': '–∫–∞–∫',
    'how about': '–∫–∞–∫ –Ω–∞—Å—á–µ—Ç',
    'this': '—ç—Ç–æ—Ç',
    'China': '–ö–∏—Ç–∞–π',
    'noon': '–ø–æ–ª–¥–µ–Ω—å',
    'midday': '–ø–æ–ª–¥–µ–Ω—å',
    'to live': '–∂–∏—Ç—å',
    'to reside': '–ø—Ä–æ–∂–∏–≤–∞—Ç—å',
    'table': '—Å—Ç–æ–ª',
    'desk': '—Å—Ç–æ–ª',
    'character': '–∏–µ—Ä–æ–≥–ª–∏—Ñ',
    'word': '—Å–ª–æ–≤–æ',
    'yesterday': '–≤—á–µ—Ä–∞',
    'to sit': '—Å–∏–¥–µ—Ç—å',
    'to do': '–¥–µ–ª–∞—Ç—å',
    'to make': '–¥–µ–ª–∞—Ç—å',
}

def convert_pinyin_to_numbered(pinyin: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç pinyin —Å —Ç–æ–Ω–∞–º–∏ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç"""
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –º–µ–∂–¥—É —Å–ª–æ–≥–∞–º–∏ –¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö —Å–ª–æ–≤
    # –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏
    result = pinyin
    
    # –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ —Ç–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–ª–∞—Å–Ω—ã–µ
    for tone_char, numbered in TONE_MARKS.items():
        result = result.replace(tone_char, numbered)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞
    result = result.replace(' ', '')
    
    return result

def translate_to_russian(english_translations: List[str]) -> str:
    """–ü—Ä–æ—Å—Ç–æ–π –ø–µ—Ä–µ–≤–æ–¥ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ —Ä—É—Å—Å–∫–∏–π"""
    translations = []
    seen = set()
    
    for eng in english_translations[:4]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 4 –ø–µ—Ä–µ–≤–æ–¥–∞
        eng_clean = eng.lower().strip()
        
        # –£–±–∏—Ä–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–æ–º–µ—Ç–∫–∏ CL:, [w√®i] –∏ —Ç.–¥.
        eng_clean = re.sub(r'CL:.*', '', eng_clean).strip()
        eng_clean = re.sub(r'\[.*?\]', '', eng_clean).strip()
        eng_clean = re.sub(r'\(.*?\)', '', eng_clean).strip()
        eng_clean = re.sub(r'[|]', ' ', eng_clean).strip()
        
        if not eng_clean or eng_clean in seen:
            continue
            
        seen.add(eng_clean)
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if eng_clean in COMMON_TRANSLATIONS:
            translations.append(COMMON_TRANSLATIONS[eng_clean])
        else:
            # –ò—â–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –Ω–∞—á–∞–ª—É —Ñ—Ä–∞–∑—ã
            found = False
            for eng_key, rus_val in COMMON_TRANSLATIONS.items():
                if eng_clean.startswith(eng_key) or eng_key.startswith(eng_clean):
                    if rus_val not in translations:
                        translations.append(rus_val)
                    found = True
                    break
            
            # –ï—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–µ—Ç, –±–µ—Ä–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–π (–±—É–¥–µ—Ç –ø–æ–Ω—è—Ç–Ω–æ —á—Ç–æ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏)
            if not found and len(translations) < 2:
                translations.append(eng_clean)
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
    if not translations and english_translations:
        return english_translations[0].split('CL:')[0].strip()
    
    return ', '.join(translations[:2])  # –ú–∞–∫—Å–∏–º—É–º 2 –ø–µ—Ä–µ–≤–æ–¥–∞

def download_hsk_level(level: int) -> List[Dict]:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç HSK —Å–ª–æ–≤–∞—Ä—å —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è"""
    url = f"https://raw.githubusercontent.com/clem109/hsk-vocabulary/master/hsk-vocab-json/hsk-level-{level}.json"
    print(f"üì• –ó–∞–≥—Ä—É–∂–∞—é HSK {level}...")
    
    response = requests.get(url)
    response.raise_for_status()
    
    data = response.json()
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} —Å–ª–æ–≤")
    
    return data

def convert_to_our_format(hsk_data: List[Dict], level: int) -> Dict:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ –Ω–∞—à —Ñ–æ—Ä–º–∞—Ç"""
    words = []
    
    for item in hsk_data:
        pinyin_numbered = convert_pinyin_to_numbered(item['pinyin'])
        russian = translate_to_russian(item['translations'])
        
        words.append({
            'chinese': item['hanzi'],
            'pinyin': pinyin_numbered,
            'russian': russian,
            'hskLevel': level
        })
    
    return {
        'name': f'HSK {level}',
        'description': f'HSK —É—Ä–æ–≤–µ–Ω—å {level} ({len(words)} —Å–ª–æ–≤)',
        'color': ['green', 'blue', 'cyan', 'purple', 'pink', 'orange'][level - 1],
        'words': words,
        'version': '1.0',
        'source': 'github.com/clem109/hsk-vocabulary'
    }

def main():
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ 6 —É—Ä–æ–≤–Ω–µ–π HSK"""
    for level in range(1, 7):
        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º
            hsk_data = download_hsk_level(level)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
            print(f"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é HSK {level}...")
            our_format = convert_to_our_format(hsk_data, level)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            filename = f'../examples/hsk{level}_from_clem.json'
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(our_format, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}\n")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ HSK {level}: {e}\n")

if __name__ == '__main__':
    main()
